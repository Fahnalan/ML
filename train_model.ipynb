{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62ed5b18-d7df-44d6-bb25-836d795251f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import pickle\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "336dc173-6144-416d-831e-cbab1faf6723",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "industries = {\n",
    "    'agro': ['CPF.BK', 'CBG.BK', 'OSP.BK', 'ITC.BK', 'BTG.BK'],\n",
    "    'consump': ['AURA.BK', 'STGT.BK', 'BLC.BK', 'SNPS.BK', 'SABINA.BK'],\n",
    "    'fincial': ['KBANK.BK', 'KTB.BK', 'SCB.BK', 'BBL.BK', 'TISCO.BK'],\n",
    "    'indus': ['PTTGC.BK', 'SCGP.BK', 'IVL.BK', 'MCS.BK', 'TSTH.BK'],\n",
    "    'propcon': ['SCC.BK', 'CPN.BK', 'WHA.BK', 'TOA.BK', 'AP.BK'],\n",
    "    'resource': ['PTTEP.BK', 'BCP.BK', 'PTT.BK', 'TOP.BK', 'GPSC.BK'],\n",
    "    'service': ['CPALL.BK', 'AOT.BK', 'BDMS.BK', 'HMPRO.BK', 'MINT.BK'],\n",
    "    'tech': ['ADVANC.BK', 'TRUE.BK', 'DELTA.BK', 'CCET.BK', 'KCE.BK']\n",
    "}\n",
    "\n",
    "def create_sequences(data, sequence_length=60):\n",
    "    X, y = [], []\n",
    "    for i in range(sequence_length, len(data)):\n",
    "        X.append(data[i-sequence_length:i, 0])\n",
    "        y.append(data[i, 0])\n",
    "    return np.array(X).reshape(-1, sequence_length, 1), np.array(y)\n",
    "\n",
    "def build_model(input_shape, lstm_units=50, dense_units=25, dropout_rate=0.2):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=lstm_units, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(units=lstm_units, return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(units=lstm_units))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units=dense_units))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "def run_tuner(x_train, y_train, input_shape, project_name):\n",
    "    def model_builder(hp):\n",
    "        return build_model(\n",
    "            input_shape=input_shape,\n",
    "            lstm_units=hp.Choice('lstm_units', [32, 64, 100, 128]),\n",
    "            dropout_rate=hp.Choice('dropout_rate', [0.1, 0.2, 0.3]),\n",
    "            dense_units=hp.Choice('dense_units', [16, 25, 50])\n",
    "        )\n",
    "\n",
    "    tuner = kt.RandomSearch(\n",
    "        model_builder,\n",
    "        objective='val_loss',\n",
    "        max_trials=3,\n",
    "        executions_per_trial=1,\n",
    "        directory='tuning_logs',\n",
    "        project_name=project_name\n",
    "    )\n",
    "\n",
    "    tuner.search(x_train, y_train, validation_split=0.2, epochs=30,\n",
    "                 batch_size=32, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
    "\n",
    "    best_model = tuner.get_best_models(1)[0]\n",
    "    best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "    return best_model, best_hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2986dcce-f9ff-4df1-b877-60c486ee4137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 00m 22s]\n",
      "val_loss: 0.00047763032489456236\n",
      "\n",
      "Best val_loss So Far: 0.00037706168950535357\n",
      "Total elapsed time: 00h 01m 23s\n",
      "✅ Best config for tech: {'lstm_units': 32, 'dropout_rate': 0.1, 'dense_units': 25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 28 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "# Generate tuner per industry\n",
    "industry_configs = {}\n",
    "\n",
    "for industry, stocks in industries.items():\n",
    "    base_stock = stocks[0]\n",
    "    print(f\"\\n🎯 Tuning industry config for {industry} using {base_stock}...\")\n",
    "\n",
    "    data_path = os.path.join(\"data\", industry, f\"{base_stock}.csv\")\n",
    "    df = pd.read_csv(data_path)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df.set_index('Date', inplace=True)\n",
    "    df = df[['Close']]\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(df)\n",
    "    train_data, _ = train_test_split(scaled_data, train_size=0.8, shuffle=False)\n",
    "    x_train, y_train = create_sequences(train_data)\n",
    "\n",
    "    best_model, best_hp = run_tuner(x_train, y_train, input_shape=(x_train.shape[1], 1), project_name=f\"{industry}_baseline\")\n",
    "    industry_configs[industry] = {\n",
    "        'lstm_units': best_hp.get('lstm_units'),\n",
    "        'dropout_rate': best_hp.get('dropout_rate'),\n",
    "        'dense_units': best_hp.get('dense_units')\n",
    "    }\n",
    "    print(f\"✅ Best config for {industry}: {industry_configs[industry]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5134c95-7deb-4ed5-9fad-c9fe186c48be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agro': {'lstm_units': 128, 'dropout_rate': 0.2, 'dense_units': 16},\n",
       " 'consump': {'lstm_units': 128, 'dropout_rate': 0.1, 'dense_units': 25},\n",
       " 'fincial': {'lstm_units': 100, 'dropout_rate': 0.2, 'dense_units': 25},\n",
       " 'indus': {'lstm_units': 100, 'dropout_rate': 0.3, 'dense_units': 50},\n",
       " 'propcon': {'lstm_units': 128, 'dropout_rate': 0.2, 'dense_units': 50},\n",
       " 'resource': {'lstm_units': 100, 'dropout_rate': 0.1, 'dense_units': 16},\n",
       " 'service': {'lstm_units': 100, 'dropout_rate': 0.3, 'dense_units': 16},\n",
       " 'tech': {'lstm_units': 32, 'dropout_rate': 0.1, 'dense_units': 25}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "industry_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64baa28f-864a-4a50-9aea-e6ad49a6fb7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📦 Training model for CPF.BK using agro config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 120ms/step - loss: 0.0800 - val_loss: 0.0175\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - loss: 0.0078 - val_loss: 0.0046\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 0.0060 - val_loss: 0.0033\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - loss: 0.0047 - val_loss: 0.0034\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - loss: 0.0042 - val_loss: 0.0033\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 175ms/step - loss: 0.0035 - val_loss: 0.0016\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 141ms/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 167ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 197ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 322ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 223ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 190ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 191ms/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 195ms/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 365ms/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 279ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 214ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 169ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0018 - val_loss: 9.7596e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 0.0018 - val_loss: 9.7826e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 145ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0020 - val_loss: 9.3718e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 143ms/step - loss: 0.0016 - val_loss: 9.5523e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0015 - val_loss: 9.2803e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 0.0016 - val_loss: 8.9556e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 0.0015 - val_loss: 8.9703e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 0.0015 - val_loss: 9.4162e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 0.0013 - val_loss: 8.4190e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "✅ Model and scaler saved for CPF.BK\n",
      "\n",
      "📦 Training model for CBG.BK using agro config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 156ms/step - loss: 0.1068 - val_loss: 0.0132\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0082 - val_loss: 0.0058\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0063 - val_loss: 0.0021\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - loss: 0.0055 - val_loss: 0.0029\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 0.0045 - val_loss: 0.0027\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - loss: 0.0044 - val_loss: 0.0014\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 0.0056 - val_loss: 0.0028\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 0.0047 - val_loss: 0.0027\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - loss: 0.0034 - val_loss: 0.0013\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 0.0032 - val_loss: 0.0014\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - loss: 0.0026 - val_loss: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 0.0031 - val_loss: 9.7270e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0024 - val_loss: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - loss: 0.0026 - val_loss: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - loss: 0.0023 - val_loss: 8.5935e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 0.0027 - val_loss: 9.7237e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 0.0021 - val_loss: 7.7715e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 0.0020 - val_loss: 7.5846e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 252ms/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 360ms/step - loss: 0.0024 - val_loss: 7.0938e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 206ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - loss: 0.0022 - val_loss: 6.7370e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - loss: 0.0018 - val_loss: 7.0516e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0021 - val_loss: 6.4592e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 284ms/step - loss: 0.0020 - val_loss: 7.8931e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - loss: 0.0017 - val_loss: 6.5381e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0018 - val_loss: 7.5456e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - loss: 0.0015 - val_loss: 6.5596e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0017 - val_loss: 7.5643e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 0.0017 - val_loss: 6.6756e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - loss: 0.0019 - val_loss: 5.9246e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0015 - val_loss: 9.4621e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 237ms/step - loss: 0.0015 - val_loss: 6.6566e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "✅ Model and scaler saved for CBG.BK\n",
      "\n",
      "📦 Training model for OSP.BK using agro config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 144ms/step - loss: 0.1223 - val_loss: 0.0158\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0062 - val_loss: 0.0084\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 186ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 337ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 253ms/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 184ms/step - loss: 0.0026 - val_loss: 9.3671e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 223ms/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 186ms/step - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - loss: 0.0024 - val_loss: 8.4224e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0021 - val_loss: 9.5040e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - loss: 0.0020 - val_loss: 8.4944e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0016 - val_loss: 9.9593e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0017 - val_loss: 7.3601e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 0.0018 - val_loss: 8.2526e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0016 - val_loss: 9.4289e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0018 - val_loss: 7.4464e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 0.0016 - val_loss: 8.7360e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 0.0016 - val_loss: 6.1010e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0016 - val_loss: 5.3364e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0014 - val_loss: 7.4122e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0015 - val_loss: 8.7486e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 0.0015 - val_loss: 8.8177e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0012 - val_loss: 7.8286e-04\n",
      "✅ Model and scaler saved for OSP.BK\n",
      "\n",
      "📦 Training model for ITC.BK using agro config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step - loss: 0.0521 - val_loss: 0.0068\n",
      "Epoch 2/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0107 - val_loss: 0.0130\n",
      "Epoch 3/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 4/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0069 - val_loss: 0.0074\n",
      "Epoch 5/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0061 - val_loss: 0.0053\n",
      "Epoch 6/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0056 - val_loss: 0.0073\n",
      "Epoch 7/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0064 - val_loss: 0.0094\n",
      "Epoch 8/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0064 - val_loss: 0.0083\n",
      "Epoch 9/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0051 - val_loss: 0.0084\n",
      "Epoch 10/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.0048 - val_loss: 0.0080\n",
      "Epoch 11/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 12/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 13/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0055 - val_loss: 0.0060\n",
      "Epoch 14/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 15/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 16/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0049 - val_loss: 0.0066\n",
      "Epoch 17/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0051 - val_loss: 0.0090\n",
      "Epoch 18/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0049 - val_loss: 0.0108\n",
      "Epoch 19/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0052 - val_loss: 0.0083\n",
      "Epoch 20/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - loss: 0.0043 - val_loss: 0.0058\n",
      "Epoch 21/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 22/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0042 - val_loss: 0.0063\n",
      "Epoch 23/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0044 - val_loss: 0.0070\n",
      "Epoch 24/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0042 - val_loss: 0.0054\n",
      "Epoch 25/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 26/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 27/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 28/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 29/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 30/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0042 - val_loss: 0.0056\n",
      "Epoch 31/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0038 - val_loss: 0.0061\n",
      "Epoch 32/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 33/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 34/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 35/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 36/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 37/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 38/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 39/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 40/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0038 - val_loss: 0.0018\n",
      "Epoch 41/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 42/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 43/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 44/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 45/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 46/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 47/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 48/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 49/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 50/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "✅ Model and scaler saved for ITC.BK\n",
      "\n",
      "📦 Training model for BTG.BK using agro config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - loss: 0.0799 - val_loss: 0.0019\n",
      "Epoch 2/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0085 - val_loss: 0.0019\n",
      "Epoch 3/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0076 - val_loss: 0.0024\n",
      "Epoch 4/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0067 - val_loss: 0.0032\n",
      "Epoch 5/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0064 - val_loss: 0.0038\n",
      "Epoch 6/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0058 - val_loss: 0.0035\n",
      "Epoch 7/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0062 - val_loss: 0.0056\n",
      "Epoch 8/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0073 - val_loss: 0.0028\n",
      "Epoch 9/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0054 - val_loss: 0.0018\n",
      "Epoch 10/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0049 - val_loss: 0.0017\n",
      "Epoch 11/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0040 - val_loss: 0.0018\n",
      "Epoch 12/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0041 - val_loss: 0.0019\n",
      "Epoch 13/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 14/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0058 - val_loss: 0.0017\n",
      "Epoch 15/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0041 - val_loss: 0.0014\n",
      "Epoch 16/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0049 - val_loss: 0.0013\n",
      "Epoch 17/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0041 - val_loss: 0.0013\n",
      "Epoch 18/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0042 - val_loss: 0.0018\n",
      "Epoch 19/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0044 - val_loss: 0.0012\n",
      "Epoch 20/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0033 - val_loss: 0.0012\n",
      "Epoch 21/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0033 - val_loss: 0.0013\n",
      "Epoch 22/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0033 - val_loss: 0.0012\n",
      "Epoch 23/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0031 - val_loss: 0.0012\n",
      "Epoch 24/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 25/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 26/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0029 - val_loss: 0.0012\n",
      "Epoch 27/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 140ms/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 28/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0049 - val_loss: 0.0013\n",
      "Epoch 29/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 30/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0039 - val_loss: 0.0011\n",
      "Epoch 31/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0024 - val_loss: 9.4438e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 33/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 34/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0029 - val_loss: 8.9339e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 36/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0030 - val_loss: 9.3642e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0028 - val_loss: 8.7307e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 39/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0029 - val_loss: 8.7612e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 41/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0028 - val_loss: 9.8791e-04\n",
      "✅ Model and scaler saved for BTG.BK\n",
      "\n",
      "📦 Training model for AURA.BK using consump config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 0.1170 - val_loss: 0.0085\n",
      "Epoch 2/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0166 - val_loss: 0.0144\n",
      "Epoch 3/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0138 - val_loss: 0.0078\n",
      "Epoch 4/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0086 - val_loss: 0.0075\n",
      "Epoch 5/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0062 - val_loss: 0.0090\n",
      "Epoch 6/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0056 - val_loss: 0.0099\n",
      "Epoch 7/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0045 - val_loss: 0.0095\n",
      "Epoch 8/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0049 - val_loss: 0.0093\n",
      "Epoch 9/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0046 - val_loss: 0.0086\n",
      "Epoch 10/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0044 - val_loss: 0.0085\n",
      "Epoch 11/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0048 - val_loss: 0.0076\n",
      "Epoch 12/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0047 - val_loss: 0.0076\n",
      "Epoch 13/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0043 - val_loss: 0.0075\n",
      "Epoch 14/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0049 - val_loss: 0.0073\n",
      "Epoch 15/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0041 - val_loss: 0.0073\n",
      "Epoch 16/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0044 - val_loss: 0.0078\n",
      "Epoch 17/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0042 - val_loss: 0.0075\n",
      "Epoch 18/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0043 - val_loss: 0.0069\n",
      "Epoch 19/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0038 - val_loss: 0.0069\n",
      "Epoch 20/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0053 - val_loss: 0.0067\n",
      "Epoch 21/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0040 - val_loss: 0.0073\n",
      "Epoch 22/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0034 - val_loss: 0.0073\n",
      "Epoch 23/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.0047 - val_loss: 0.0064\n",
      "Epoch 24/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0038 - val_loss: 0.0063\n",
      "Epoch 25/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 458ms/step - loss: 0.0036 - val_loss: 0.0066\n",
      "Epoch 26/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 263ms/step - loss: 0.0043 - val_loss: 0.0061\n",
      "Epoch 27/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0040 - val_loss: 0.0063\n",
      "Epoch 28/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0041 - val_loss: 0.0061\n",
      "Epoch 29/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - loss: 0.0035 - val_loss: 0.0068\n",
      "Epoch 30/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 241ms/step - loss: 0.0036 - val_loss: 0.0061\n",
      "Epoch 31/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 252ms/step - loss: 0.0033 - val_loss: 0.0061\n",
      "Epoch 32/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 318ms/step - loss: 0.0038 - val_loss: 0.0062\n",
      "Epoch 33/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.0036 - val_loss: 0.0058\n",
      "Epoch 34/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0039 - val_loss: 0.0057\n",
      "Epoch 35/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0034 - val_loss: 0.0058\n",
      "Epoch 36/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0035 - val_loss: 0.0055\n",
      "Epoch 37/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 38/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0039 - val_loss: 0.0056\n",
      "Epoch 39/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0031 - val_loss: 0.0060\n",
      "Epoch 40/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0029 - val_loss: 0.0058\n",
      "Epoch 41/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0039 - val_loss: 0.0063\n",
      "Epoch 42/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0037 - val_loss: 0.0055\n",
      "Epoch 43/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0036 - val_loss: 0.0050\n",
      "Epoch 44/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 45/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 46/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0040 - val_loss: 0.0050\n",
      "Epoch 47/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 48/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0032 - val_loss: 0.0053\n",
      "Epoch 49/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0030 - val_loss: 0.0049\n",
      "Epoch 50/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0024 - val_loss: 0.0052\n",
      "✅ Model and scaler saved for AURA.BK\n",
      "\n",
      "📦 Training model for STGT.BK using consump config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 133ms/step - loss: 0.1016 - val_loss: 0.0063\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - loss: 0.0078 - val_loss: 0.0012\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 0.0032 - val_loss: 2.7752e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0026 - val_loss: 2.7348e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - loss: 0.0026 - val_loss: 3.3492e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - loss: 0.0036 - val_loss: 2.6031e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 0.0026 - val_loss: 3.8730e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 0.0021 - val_loss: 2.1723e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - loss: 0.0022 - val_loss: 2.2948e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 0.0027 - val_loss: 1.8554e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - loss: 0.0027 - val_loss: 2.5773e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 214ms/step - loss: 0.0021 - val_loss: 4.3288e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - loss: 0.0022 - val_loss: 1.5121e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 0.0019 - val_loss: 1.5958e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 0.0019 - val_loss: 3.0609e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 0.0020 - val_loss: 3.4876e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - loss: 0.0016 - val_loss: 2.1745e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0020 - val_loss: 2.8578e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 147ms/step - loss: 0.0018 - val_loss: 1.4068e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 182ms/step - loss: 0.0025 - val_loss: 2.9525e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - loss: 0.0018 - val_loss: 2.6940e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 153ms/step - loss: 0.0017 - val_loss: 1.9690e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 189ms/step - loss: 0.0016 - val_loss: 1.3356e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 159ms/step - loss: 0.0015 - val_loss: 3.8742e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0016 - val_loss: 2.6786e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - loss: 0.0014 - val_loss: 1.3826e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - loss: 0.0018 - val_loss: 1.4022e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - loss: 0.0014 - val_loss: 2.9179e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - loss: 0.0015 - val_loss: 2.3387e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - loss: 0.0013 - val_loss: 1.6259e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - loss: 0.0015 - val_loss: 1.2988e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 0.0013 - val_loss: 1.4373e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 0.0013 - val_loss: 1.6968e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - loss: 0.0013 - val_loss: 1.2639e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - loss: 0.0014 - val_loss: 1.1740e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 0.0016 - val_loss: 2.8787e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - loss: 0.0011 - val_loss: 1.8384e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 228ms/step - loss: 0.0011 - val_loss: 1.3737e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 168ms/step - loss: 0.0013 - val_loss: 1.4042e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 182ms/step - loss: 0.0016 - val_loss: 1.6421e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 180ms/step - loss: 0.0014 - val_loss: 1.1114e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 217ms/step - loss: 0.0011 - val_loss: 1.9625e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 266ms/step - loss: 0.0013 - val_loss: 1.3503e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 182ms/step - loss: 0.0017 - val_loss: 1.0005e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 185ms/step - loss: 0.0019 - val_loss: 2.3289e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 193ms/step - loss: 0.0012 - val_loss: 1.1159e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 158ms/step - loss: 0.0013 - val_loss: 9.4407e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 0.0014 - val_loss: 9.0144e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 0.0012 - val_loss: 2.2098e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - loss: 0.0011 - val_loss: 1.0448e-04\n",
      "✅ Model and scaler saved for STGT.BK\n",
      "\n",
      "📦 Training model for BLC.BK using consump config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 180ms/step - loss: 0.0320 - val_loss: 0.0212\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0053 - val_loss: 0.0176\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0045 - val_loss: 0.0166\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0039 - val_loss: 0.0115\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0031 - val_loss: 0.0058\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0036 - val_loss: 0.0050\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0038 - val_loss: 0.0131\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0031 - val_loss: 0.0097\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0030 - val_loss: 0.0095\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0032 - val_loss: 0.0069\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0033 - val_loss: 0.0064\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0033 - val_loss: 0.0059\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0027 - val_loss: 0.0087\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0034 - val_loss: 0.0086\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0031 - val_loss: 0.0067\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0030 - val_loss: 0.0058\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0026 - val_loss: 0.0085\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0031 - val_loss: 0.0093\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0033 - val_loss: 0.0065\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0028 - val_loss: 0.0081\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0027 - val_loss: 0.0107\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0022 - val_loss: 0.0076\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0029 - val_loss: 0.0087\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0027 - val_loss: 0.0070\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0024 - val_loss: 0.0064\n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.0029 - val_loss: 0.0089\n",
      "Epoch 37/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0025 - val_loss: 0.0106\n",
      "Epoch 38/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 39/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 40/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 41/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0020 - val_loss: 0.0072\n",
      "Epoch 42/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 43/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0024 - val_loss: 0.0060\n",
      "Epoch 44/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0020 - val_loss: 0.0079\n",
      "Epoch 45/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 46/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 47/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 48/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 49/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 50/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0020 - val_loss: 0.0043\n",
      "✅ Model and scaler saved for BLC.BK\n",
      "\n",
      "📦 Training model for SNPS.BK using consump config\n",
      "⚠️ Not enough test data for SNPS.BK. Skipping...\n",
      "\n",
      "📦 Training model for SABINA.BK using consump config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - loss: 0.0567 - val_loss: 0.0229\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - loss: 0.0053 - val_loss: 0.0037\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 173ms/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 162ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0014 - val_loss: 0.0056\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0013 - val_loss: 0.0075\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 0.0014 - val_loss: 0.0065\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 145ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 217ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 9.0012e-04 - val_loss: 0.0030\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 250ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 207ms/step - loss: 8.8078e-04 - val_loss: 0.0025\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - loss: 9.6124e-04 - val_loss: 0.0027\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 9.9789e-04 - val_loss: 0.0017\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 285ms/step - loss: 7.6323e-04 - val_loss: 0.0014\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 8.2317e-04 - val_loss: 0.0016\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 8.1759e-04 - val_loss: 0.0014\n",
      "✅ Model and scaler saved for SABINA.BK\n",
      "\n",
      "📦 Training model for KBANK.BK using fincial config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - loss: 0.0680 - val_loss: 0.0032\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.0077 - val_loss: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - loss: 0.0053 - val_loss: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - loss: 0.0051 - val_loss: 0.0011\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0043 - val_loss: 0.0015\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - loss: 0.0048 - val_loss: 8.8142e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - loss: 0.0041 - val_loss: 8.9997e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - loss: 0.0042 - val_loss: 0.0011\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0038 - val_loss: 0.0016\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - loss: 0.0046 - val_loss: 0.0023\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 0.0035 - val_loss: 7.3590e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - loss: 0.0035 - val_loss: 6.1049e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0032 - val_loss: 8.2790e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - loss: 0.0032 - val_loss: 6.0474e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0035 - val_loss: 5.1970e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - loss: 0.0028 - val_loss: 6.0627e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - loss: 0.0026 - val_loss: 8.6731e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - loss: 0.0025 - val_loss: 8.3470e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - loss: 0.0026 - val_loss: 6.0573e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0022 - val_loss: 4.6291e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0022 - val_loss: 4.6667e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - loss: 0.0022 - val_loss: 8.8708e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - loss: 0.0023 - val_loss: 4.4816e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0023 - val_loss: 6.6836e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - loss: 0.0022 - val_loss: 4.7630e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.0019 - val_loss: 4.9211e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0019 - val_loss: 4.2545e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0020 - val_loss: 4.2195e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 0.0020 - val_loss: 4.6984e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 0.0019 - val_loss: 9.1448e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 0.0022 - val_loss: 4.3232e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 0.0016 - val_loss: 4.0515e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 0.0015 - val_loss: 4.0711e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 168ms/step - loss: 0.0017 - val_loss: 3.9636e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - loss: 0.0017 - val_loss: 4.7266e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - loss: 0.0014 - val_loss: 5.6910e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - loss: 0.0016 - val_loss: 3.8429e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - loss: 0.0017 - val_loss: 6.0384e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0015 - val_loss: 4.1511e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0013 - val_loss: 3.8800e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - loss: 0.0015 - val_loss: 3.7433e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - loss: 0.0014 - val_loss: 4.1226e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0014 - val_loss: 6.5460e-04\n",
      "✅ Model and scaler saved for KBANK.BK\n",
      "\n",
      "📦 Training model for KTB.BK using fincial config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 119ms/step - loss: 0.0251 - val_loss: 0.0020\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - loss: 0.0023 - val_loss: 9.8025e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0013 - val_loss: 8.3350e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0012 - val_loss: 7.5801e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 0.0011 - val_loss: 8.7592e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0010 - val_loss: 0.0021\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - loss: 0.0011 - val_loss: 6.8942e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 9.5255e-04 - val_loss: 7.8550e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - loss: 9.3067e-04 - val_loss: 8.2827e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 175ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 8.5880e-04 - val_loss: 6.6472e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 8.1826e-04 - val_loss: 6.1335e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 7.6957e-04 - val_loss: 6.1159e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 8.4322e-04 - val_loss: 0.0014\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 9.1317e-04 - val_loss: 0.0011\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - loss: 7.8604e-04 - val_loss: 6.6092e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 8.8406e-04 - val_loss: 5.5417e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 6.7746e-04 - val_loss: 9.0154e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 7.6451e-04 - val_loss: 0.0031\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - loss: 8.4511e-04 - val_loss: 5.9613e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - loss: 7.4365e-04 - val_loss: 4.8777e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - loss: 7.0996e-04 - val_loss: 9.7502e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - loss: 7.2562e-04 - val_loss: 5.2145e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - loss: 7.8770e-04 - val_loss: 4.4137e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - loss: 6.8319e-04 - val_loss: 4.4424e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - loss: 6.7870e-04 - val_loss: 8.6384e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 6.4779e-04 - val_loss: 5.6387e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 6.2555e-04 - val_loss: 5.0201e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 6.4732e-04 - val_loss: 0.0017\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 7.0864e-04 - val_loss: 5.5719e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 6.1758e-04 - val_loss: 4.9713e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 8.3343e-04 - val_loss: 6.5589e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 6.1592e-04 - val_loss: 5.2105e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 5.3490e-04 - val_loss: 5.7057e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - loss: 5.4027e-04 - val_loss: 4.3047e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 5.2249e-04 - val_loss: 3.6097e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 5.6021e-04 - val_loss: 3.4360e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 4.9404e-04 - val_loss: 7.1379e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 5.5450e-04 - val_loss: 3.4667e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 5.0398e-04 - val_loss: 3.4329e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 5.3248e-04 - val_loss: 5.3262e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 5.5176e-04 - val_loss: 3.2192e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 5.5061e-04 - val_loss: 5.7185e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 4.2892e-04 - val_loss: 7.5303e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 5.1467e-04 - val_loss: 9.1396e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 5.5234e-04 - val_loss: 4.5643e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 5.1967e-04 - val_loss: 0.0010\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - loss: 5.0086e-04 - val_loss: 3.0069e-04\n",
      "✅ Model and scaler saved for KTB.BK\n",
      "\n",
      "📦 Training model for SCB.BK using fincial config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - loss: 0.0708 - val_loss: 0.0043\n",
      "Epoch 2/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 474ms/step - loss: 0.0075 - val_loss: 0.0149\n",
      "Epoch 3/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0043 - val_loss: 0.0075\n",
      "Epoch 4/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0037 - val_loss: 0.0063\n",
      "Epoch 5/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 6/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0030 - val_loss: 0.0058\n",
      "Epoch 7/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 8/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 9/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 10/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0029 - val_loss: 0.0051\n",
      "Epoch 11/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 12/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 13/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 14/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 15/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 16/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 17/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 18/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 19/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 20/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 21/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 22/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 23/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 24/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 25/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 26/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 27/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 28/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 29/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 30/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 31/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 32/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 33/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 34/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 35/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 36/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 37/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 38/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 39/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 40/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 41/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 42/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 43/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 44/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 45/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 46/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 47/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 48/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 49/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 50/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0013 - val_loss: 0.0029\n",
      "✅ Model and scaler saved for SCB.BK\n",
      "\n",
      "📦 Training model for BBL.BK using fincial config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 101ms/step - loss: 0.0524 - val_loss: 0.0567\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - loss: 0.0108 - val_loss: 0.0043\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0046 - val_loss: 0.0019\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0041 - val_loss: 0.0019\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0039 - val_loss: 0.0066\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0033 - val_loss: 0.0085\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0026 - val_loss: 8.7832e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0023 - val_loss: 8.0060e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0023 - val_loss: 7.7039e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0023 - val_loss: 7.7093e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0018 - val_loss: 6.5660e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0015 - val_loss: 9.6858e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0016 - val_loss: 9.2375e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0014 - val_loss: 6.6907e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0014 - val_loss: 7.0240e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0014 - val_loss: 6.7526e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0015 - val_loss: 7.7688e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0011 - val_loss: 5.8185e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0012 - val_loss: 9.0973e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0015 - val_loss: 6.4770e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - loss: 0.0014 - val_loss: 7.1428e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0012 - val_loss: 8.8858e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.0013 - val_loss: 6.0207e-04\n",
      "✅ Model and scaler saved for BBL.BK\n",
      "\n",
      "📦 Training model for TISCO.BK using fincial config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - loss: 0.0729 - val_loss: 0.0172\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - loss: 0.0054 - val_loss: 0.0034\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0032 - val_loss: 3.6418e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0026 - val_loss: 3.3347e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0026 - val_loss: 3.1942e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0023 - val_loss: 3.9059e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0021 - val_loss: 9.6831e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0021 - val_loss: 6.7064e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0023 - val_loss: 5.2953e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0021 - val_loss: 6.6196e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0018 - val_loss: 5.7524e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0017 - val_loss: 7.6165e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0016 - val_loss: 4.4551e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0016 - val_loss: 6.3054e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0015 - val_loss: 2.8245e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0020 - val_loss: 2.7216e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0014 - val_loss: 5.8826e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0013 - val_loss: 4.4152e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0011 - val_loss: 9.5579e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0014 - val_loss: 4.5915e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0011 - val_loss: 2.7199e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0013 - val_loss: 2.4302e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0010 - val_loss: 7.0829e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0011 - val_loss: 5.8565e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 9.2923e-04 - val_loss: 2.4936e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 9.3573e-04 - val_loss: 2.3045e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 9.3266e-04 - val_loss: 3.8095e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0010 - val_loss: 2.5357e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 9.0337e-04 - val_loss: 4.9314e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 9.6533e-04 - val_loss: 2.5421e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 8.2452e-04 - val_loss: 2.3541e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0010 - val_loss: 8.7880e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 9.9470e-04 - val_loss: 0.0018\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 9.2018e-04 - val_loss: 3.0959e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 8.4390e-04 - val_loss: 5.5718e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 9.1655e-04 - val_loss: 2.0465e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 8.3321e-04 - val_loss: 4.7080e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 8.3305e-04 - val_loss: 2.0087e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 8.1240e-04 - val_loss: 2.8029e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 6.9643e-04 - val_loss: 4.6352e-04\n",
      "✅ Model and scaler saved for TISCO.BK\n",
      "\n",
      "📦 Training model for PTTGC.BK using indus config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 103ms/step - loss: 0.1549 - val_loss: 0.0015\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - loss: 0.0137 - val_loss: 0.0085\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0084 - val_loss: 0.0047\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0069 - val_loss: 0.0019\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0060 - val_loss: 9.4737e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0078 - val_loss: 0.0043\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0059 - val_loss: 0.0022\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0048 - val_loss: 0.0015\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0049 - val_loss: 0.0013\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0048 - val_loss: 8.3579e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0050 - val_loss: 8.5767e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0044 - val_loss: 8.9988e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0046 - val_loss: 0.0011\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0041 - val_loss: 0.0013\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0040 - val_loss: 0.0017\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0040 - val_loss: 0.0017\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0034 - val_loss: 7.5223e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0033 - val_loss: 7.4151e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0028 - val_loss: 6.9324e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0038 - val_loss: 0.0015\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0028 - val_loss: 8.3397e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0027 - val_loss: 8.1365e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0037 - val_loss: 7.6814e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0025 - val_loss: 7.5904e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0024 - val_loss: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0029 - val_loss: 7.0519e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0026 - val_loss: 9.6538e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0027 - val_loss: 9.0079e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0022 - val_loss: 6.3246e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0020 - val_loss: 6.4137e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0019 - val_loss: 8.1721e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0020 - val_loss: 6.1336e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0020 - val_loss: 7.0415e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0018 - val_loss: 8.1575e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0016 - val_loss: 6.2373e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - loss: 0.0016 - val_loss: 5.5246e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0019 - val_loss: 5.4079e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0016 - val_loss: 5.0617e-04\n",
      "✅ Model and scaler saved for PTTGC.BK\n",
      "\n",
      "📦 Training model for SCGP.BK using indus config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - loss: 0.1610 - val_loss: 0.0072\n",
      "Epoch 2/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0129 - val_loss: 0.0134\n",
      "Epoch 3/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - loss: 0.0078 - val_loss: 0.0131\n",
      "Epoch 4/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0062 - val_loss: 0.0066\n",
      "Epoch 5/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 6/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0052 - val_loss: 0.0022\n",
      "Epoch 7/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 8/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0049 - val_loss: 0.0011\n",
      "Epoch 9/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0043 - val_loss: 9.1780e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0071 - val_loss: 0.0023\n",
      "Epoch 11/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 12/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0051 - val_loss: 0.0014\n",
      "Epoch 13/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0043 - val_loss: 8.0462e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0051 - val_loss: 0.0019\n",
      "Epoch 15/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 16/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0043 - val_loss: 0.0011\n",
      "Epoch 17/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0044 - val_loss: 0.0014\n",
      "Epoch 18/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0035 - val_loss: 9.6878e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0033 - val_loss: 0.0012\n",
      "Epoch 20/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0032 - val_loss: 6.9006e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0034 - val_loss: 6.8268e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 23/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0033 - val_loss: 7.2626e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0049 - val_loss: 0.0021\n",
      "Epoch 25/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0034 - val_loss: 6.9124e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0028 - val_loss: 7.8361e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 28/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 29/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0026 - val_loss: 8.2611e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0024 - val_loss: 6.1823e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 32/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0025 - val_loss: 6.0972e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0024 - val_loss: 9.7112e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - loss: 0.0032 - val_loss: 6.3492e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0025 - val_loss: 9.7555e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 37/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0023 - val_loss: 8.8631e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 39/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0026 - val_loss: 6.0173e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0018 - val_loss: 7.0941e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0018 - val_loss: 5.7477e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 43/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0021 - val_loss: 5.6330e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0018 - val_loss: 5.5022e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0020 - val_loss: 7.5214e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0017 - val_loss: 6.0879e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 48/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 49/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0029 - val_loss: 5.7913e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0018 - val_loss: 7.6308e-04\n",
      "✅ Model and scaler saved for SCGP.BK\n",
      "\n",
      "📦 Training model for IVL.BK using indus config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - loss: 0.1350 - val_loss: 0.0065\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - loss: 0.0092 - val_loss: 0.0023\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0077 - val_loss: 0.0025\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0067 - val_loss: 0.0016\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0066 - val_loss: 0.0017\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0058 - val_loss: 0.0018\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0058 - val_loss: 0.0035\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0055 - val_loss: 0.0031\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0053 - val_loss: 0.0023\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0046 - val_loss: 0.0024\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0044 - val_loss: 0.0015\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0040 - val_loss: 0.0012\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0050 - val_loss: 0.0016\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0036 - val_loss: 0.0011\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0041 - val_loss: 0.0017\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0043 - val_loss: 0.0019\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0037 - val_loss: 9.7765e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0031 - val_loss: 0.0014\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0029 - val_loss: 9.1608e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0025 - val_loss: 8.6688e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0024 - val_loss: 9.8171e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0024 - val_loss: 8.2331e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0023 - val_loss: 8.5730e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0022 - val_loss: 8.4121e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0023 - val_loss: 8.1903e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0020 - val_loss: 8.9668e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0021 - val_loss: 8.2082e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0021 - val_loss: 9.1403e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0019 - val_loss: 7.0610e-04\n",
      "✅ Model and scaler saved for IVL.BK\n",
      "\n",
      "📦 Training model for MCS.BK using indus config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - loss: 0.1592 - val_loss: 0.0175\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0109 - val_loss: 0.0090\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0073 - val_loss: 0.0029\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0070 - val_loss: 0.0022\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0056 - val_loss: 0.0035\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0060 - val_loss: 0.0017\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0055 - val_loss: 0.0017\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0054 - val_loss: 0.0029\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0045 - val_loss: 0.0022\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0053 - val_loss: 0.0020\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0046 - val_loss: 0.0024\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.0060 - val_loss: 0.0024\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0041 - val_loss: 0.0017\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0038 - val_loss: 0.0016\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0035 - val_loss: 0.0016\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0019 - val_loss: 9.4534e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0021 - val_loss: 7.6905e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - loss: 0.0023 - val_loss: 8.4571e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0016 - val_loss: 6.0238e-04\n",
      "✅ Model and scaler saved for MCS.BK\n",
      "\n",
      "📦 Training model for TSTH.BK using indus config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.0658 - val_loss: 7.5252e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0088 - val_loss: 2.9909e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0050 - val_loss: 4.3285e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0043 - val_loss: 7.2366e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0057 - val_loss: 0.0011\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0036 - val_loss: 5.4673e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0042 - val_loss: 2.2688e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0035 - val_loss: 0.0015\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0035 - val_loss: 2.7018e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.0034 - val_loss: 6.4179e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0030 - val_loss: 1.9835e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0043 - val_loss: 7.3717e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0034 - val_loss: 5.8295e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0034 - val_loss: 5.3463e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0020 - val_loss: 4.1057e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0024 - val_loss: 6.6629e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0027 - val_loss: 1.9322e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 0.0022 - val_loss: 3.5701e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0019 - val_loss: 4.0259e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - loss: 0.0019 - val_loss: 1.7304e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0017 - val_loss: 1.5281e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0023 - val_loss: 1.5874e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0017 - val_loss: 1.8802e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0022 - val_loss: 3.1531e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0019 - val_loss: 1.6766e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0020 - val_loss: 3.6819e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0013 - val_loss: 1.4503e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0015 - val_loss: 3.7508e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0019 - val_loss: 1.4947e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0014 - val_loss: 2.4663e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0014 - val_loss: 1.6727e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0015 - val_loss: 1.3574e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0022 - val_loss: 1.9159e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0019 - val_loss: 1.7426e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0014 - val_loss: 2.9932e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0017 - val_loss: 2.0188e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0016 - val_loss: 1.5111e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.0014 - val_loss: 5.3346e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0017 - val_loss: 2.6658e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0016 - val_loss: 2.5494e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0014 - val_loss: 1.9715e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0013 - val_loss: 4.2046e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0012 - val_loss: 1.2656e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0015 - val_loss: 1.9052e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0015 - val_loss: 1.1059e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0015 - val_loss: 1.3266e-04\n",
      "✅ Model and scaler saved for TSTH.BK\n",
      "\n",
      "📦 Training model for SCC.BK using propcon config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 132ms/step - loss: 0.1064 - val_loss: 0.0043\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 0.0074 - val_loss: 0.0049\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - loss: 0.0045 - val_loss: 0.0059\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 0.0041 - val_loss: 0.0058\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 0.0028 - val_loss: 0.0049\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 0.0022 - val_loss: 9.3836e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - loss: 0.0025 - val_loss: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - loss: 0.0025 - val_loss: 7.9927e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 0.0030 - val_loss: 4.7671e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - loss: 0.0021 - val_loss: 9.8097e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - loss: 0.0017 - val_loss: 8.0505e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - loss: 0.0019 - val_loss: 8.7498e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - loss: 0.0017 - val_loss: 8.3006e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 0.0018 - val_loss: 4.6641e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 0.0017 - val_loss: 7.8058e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - loss: 0.0017 - val_loss: 9.5777e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - loss: 0.0015 - val_loss: 6.9025e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 0.0019 - val_loss: 4.1592e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - loss: 0.0021 - val_loss: 5.7007e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - loss: 0.0016 - val_loss: 4.4206e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 0.0017 - val_loss: 9.1918e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 0.0014 - val_loss: 6.2082e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - loss: 0.0011 - val_loss: 8.1661e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - loss: 0.0016 - val_loss: 6.0276e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - loss: 0.0014 - val_loss: 8.3597e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - loss: 0.0013 - val_loss: 6.3468e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 0.0013 - val_loss: 4.2761e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - loss: 0.0013 - val_loss: 5.8873e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - loss: 0.0013 - val_loss: 3.4543e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 0.0013 - val_loss: 4.4467e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - loss: 0.0011 - val_loss: 4.1766e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - loss: 0.0011 - val_loss: 6.5057e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 0.0013 - val_loss: 6.0217e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0011 - val_loss: 4.4873e-04\n",
      "✅ Model and scaler saved for SCC.BK\n",
      "\n",
      "📦 Training model for CPN.BK using propcon config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - loss: 0.1123 - val_loss: 0.0235\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - loss: 0.0104 - val_loss: 0.0075\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - loss: 0.0061 - val_loss: 0.0018\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - loss: 0.0056 - val_loss: 0.0063\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - loss: 0.0068 - val_loss: 0.0091\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - loss: 0.0064 - val_loss: 0.0020\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - loss: 0.0049 - val_loss: 0.0018\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - loss: 0.0043 - val_loss: 0.0016\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - loss: 0.0042 - val_loss: 0.0017\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 0.0040 - val_loss: 0.0017\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0032 - val_loss: 0.0014\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - loss: 0.0033 - val_loss: 0.0013\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 0.0018 - val_loss: 9.4169e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0018 - val_loss: 9.5268e-04\n",
      "✅ Model and scaler saved for CPN.BK\n",
      "\n",
      "📦 Training model for WHA.BK using propcon config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 117ms/step - loss: 0.0338 - val_loss: 0.0127\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 0.0014 - val_loss: 0.0056\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - loss: 8.3139e-04 - val_loss: 0.0018\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 8.4122e-04 - val_loss: 0.0017\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 7.8489e-04 - val_loss: 0.0013\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 9.1957e-04 - val_loss: 0.0013\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - loss: 7.6683e-04 - val_loss: 0.0013\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 8.7611e-04 - val_loss: 0.0030\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 7.5020e-04 - val_loss: 0.0012\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - loss: 7.1431e-04 - val_loss: 0.0019\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - loss: 7.1296e-04 - val_loss: 0.0055\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 7.1460e-04 - val_loss: 0.0013\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 7.9405e-04 - val_loss: 0.0011\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 7.1267e-04 - val_loss: 0.0012\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - loss: 6.9394e-04 - val_loss: 0.0017\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 6.2410e-04 - val_loss: 0.0011\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 8.8819e-04 - val_loss: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 6.0788e-04 - val_loss: 0.0011\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 6.5228e-04 - val_loss: 0.0016\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - loss: 5.7278e-04 - val_loss: 9.8545e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 6.4058e-04 - val_loss: 0.0049\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - loss: 7.2846e-04 - val_loss: 0.0014\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - loss: 5.9710e-04 - val_loss: 0.0013\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 7.2053e-04 - val_loss: 9.2266e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 5.3271e-04 - val_loss: 0.0010\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 5.0283e-04 - val_loss: 0.0013\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - loss: 5.0966e-04 - val_loss: 0.0022\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 5.3435e-04 - val_loss: 0.0027\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 5.4714e-04 - val_loss: 8.4914e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - loss: 5.7439e-04 - val_loss: 8.8732e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - loss: 6.0032e-04 - val_loss: 8.6609e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 6.1323e-04 - val_loss: 7.7330e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 5.3910e-04 - val_loss: 7.9399e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 5.3885e-04 - val_loss: 0.0019\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - loss: 4.3412e-04 - val_loss: 9.3640e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 5.1536e-04 - val_loss: 0.0010\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 4.6945e-04 - val_loss: 0.0016\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 6.2881e-04 - val_loss: 9.9827e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - loss: 5.4269e-04 - val_loss: 7.3378e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 5.4001e-04 - val_loss: 0.0011\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 4.9812e-04 - val_loss: 7.2500e-04\n",
      "✅ Model and scaler saved for WHA.BK\n",
      "\n",
      "📦 Training model for TOA.BK using propcon config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 128ms/step - loss: 0.1682 - val_loss: 0.0030\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - loss: 0.0124 - val_loss: 0.0138\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - loss: 0.0063 - val_loss: 0.0151\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - loss: 0.0057 - val_loss: 0.0150\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 0.0050 - val_loss: 0.0085\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 0.0041 - val_loss: 0.0094\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 0.0047 - val_loss: 0.0075\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 0.0037 - val_loss: 0.0085\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - loss: 0.0035 - val_loss: 0.0069\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 0.0023 - val_loss: 0.0067\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "✅ Model and scaler saved for TOA.BK\n",
      "\n",
      "📦 Training model for AP.BK using propcon config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 121ms/step - loss: 0.0891 - val_loss: 0.0131\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - loss: 0.0066 - val_loss: 0.0041\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - loss: 0.0034 - val_loss: 0.0013\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 0.0017 - val_loss: 9.6760e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 0.0014 - val_loss: 8.8638e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 0.0014 - val_loss: 9.2547e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - loss: 0.0014 - val_loss: 8.9774e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 0.0013 - val_loss: 9.9724e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 0.0012 - val_loss: 7.4614e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 0.0012 - val_loss: 8.9743e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - loss: 0.0011 - val_loss: 8.2237e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 9.4555e-04 - val_loss: 7.0369e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 0.0012 - val_loss: 6.8885e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0012 - val_loss: 6.8545e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - loss: 0.0011 - val_loss: 6.6050e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - loss: 0.0010 - val_loss: 8.7586e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 0.0012 - val_loss: 8.9244e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - loss: 0.0010 - val_loss: 6.6225e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - loss: 9.7857e-04 - val_loss: 6.3361e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - loss: 9.3162e-04 - val_loss: 5.9559e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 9.7569e-04 - val_loss: 7.5040e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 9.4837e-04 - val_loss: 8.1138e-04\n",
      "✅ Model and scaler saved for AP.BK\n",
      "\n",
      "📦 Training model for PTTEP.BK using resource config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 104ms/step - loss: 0.0650 - val_loss: 0.0015\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0038 - val_loss: 0.0014\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0031 - val_loss: 0.0013\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0025 - val_loss: 9.3147e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - loss: 0.0020 - val_loss: 8.3636e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0019 - val_loss: 7.9985e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - loss: 0.0019 - val_loss: 8.3773e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0017 - val_loss: 6.8649e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0018 - val_loss: 6.7526e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0014 - val_loss: 9.8867e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0016 - val_loss: 6.1302e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0013 - val_loss: 7.3525e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - loss: 0.0012 - val_loss: 6.8254e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0012 - val_loss: 6.0220e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0012 - val_loss: 5.7369e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0013 - val_loss: 7.3697e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0012 - val_loss: 7.7557e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0012 - val_loss: 6.5346e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0014 - val_loss: 5.6416e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0012 - val_loss: 4.9902e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0010 - val_loss: 5.0085e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0011 - val_loss: 7.9481e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0012 - val_loss: 4.8122e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0010 - val_loss: 7.8862e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0012 - val_loss: 9.3406e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 9.3500e-04 - val_loss: 8.0385e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0013 - val_loss: 8.2012e-04\n",
      "✅ Model and scaler saved for PTTEP.BK\n",
      "\n",
      "📦 Training model for BCP.BK using resource config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 105ms/step - loss: 0.0425 - val_loss: 0.0181\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0012 - val_loss: 0.0061\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0010 - val_loss: 0.0028\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 9.0734e-04 - val_loss: 9.4802e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 9.9333e-04 - val_loss: 0.0014\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0011 - val_loss: 8.1982e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 0.0011 - val_loss: 9.7290e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 9.2038e-04 - val_loss: 8.3952e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 8.7959e-04 - val_loss: 0.0028\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 9.2805e-04 - val_loss: 0.0014\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - loss: 9.6349e-04 - val_loss: 0.0027\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 8.4847e-04 - val_loss: 9.3216e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 8.4277e-04 - val_loss: 0.0014\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 9.4541e-04 - val_loss: 8.2310e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 8.8540e-04 - val_loss: 8.5649e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 8.1467e-04 - val_loss: 0.0015\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 7.9493e-04 - val_loss: 6.4134e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 7.9853e-04 - val_loss: 6.3736e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 7.0479e-04 - val_loss: 0.0032\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 8.2607e-04 - val_loss: 0.0017\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 6.4704e-04 - val_loss: 7.1315e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 7.1188e-04 - val_loss: 0.0011\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 6.5857e-04 - val_loss: 0.0011\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 6.0905e-04 - val_loss: 0.0011\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 6.5738e-04 - val_loss: 0.0013\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 5.6217e-04 - val_loss: 0.0010\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 7.0797e-04 - val_loss: 0.0018\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 6.0206e-04 - val_loss: 0.0016\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 7.2193e-04 - val_loss: 5.8194e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 9.1870e-04 - val_loss: 5.2308e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 6.2258e-04 - val_loss: 6.5808e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 5.6984e-04 - val_loss: 0.0016\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 6.3459e-04 - val_loss: 5.4003e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 5.2570e-04 - val_loss: 8.4444e-04\n",
      "✅ Model and scaler saved for BCP.BK\n",
      "\n",
      "📦 Training model for PTT.BK using resource config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - loss: 0.1121 - val_loss: 0.0144\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0115 - val_loss: 0.0029\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - loss: 0.0077 - val_loss: 0.0025\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0060 - val_loss: 0.0025\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0066 - val_loss: 0.0036\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0060 - val_loss: 0.0019\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0057 - val_loss: 0.0021\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0060 - val_loss: 0.0014\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0053 - val_loss: 0.0015\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0050 - val_loss: 0.0032\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0046 - val_loss: 0.0013\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0048 - val_loss: 0.0015\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0055 - val_loss: 0.0024\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0050 - val_loss: 0.0017\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0042 - val_loss: 0.0014\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0040 - val_loss: 0.0011\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0038 - val_loss: 0.0013\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0036 - val_loss: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0036 - val_loss: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0038 - val_loss: 0.0013\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0037 - val_loss: 0.0012\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0031 - val_loss: 0.0012\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.0029 - val_loss: 9.9710e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0035 - val_loss: 0.0014\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.0025 - val_loss: 8.7726e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0024 - val_loss: 8.7747e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0022 - val_loss: 8.5958e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0028 - val_loss: 8.8820e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0033 - val_loss: 8.2965e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0025 - val_loss: 8.0905e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0024 - val_loss: 8.1805e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0025 - val_loss: 9.0023e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0027 - val_loss: 8.2947e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0026 - val_loss: 9.4989e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.0021 - val_loss: 7.1588e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0018 - val_loss: 7.3127e-04\n",
      "✅ Model and scaler saved for PTT.BK\n",
      "\n",
      "📦 Training model for TOP.BK using resource config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.1137 - val_loss: 0.0179\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0086 - val_loss: 0.0033\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0052 - val_loss: 0.0024\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0052 - val_loss: 0.0024\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0046 - val_loss: 0.0018\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0042 - val_loss: 0.0018\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0034 - val_loss: 0.0015\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0032 - val_loss: 0.0015\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0037 - val_loss: 0.0015\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0032 - val_loss: 0.0015\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0035 - val_loss: 0.0013\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0025 - val_loss: 9.8052e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0026 - val_loss: 9.5178e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0026 - val_loss: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0022 - val_loss: 8.7959e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0016 - val_loss: 8.8088e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0016 - val_loss: 7.9375e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0018 - val_loss: 7.4315e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0017 - val_loss: 6.8855e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0018 - val_loss: 7.6158e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0016 - val_loss: 9.0388e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0017 - val_loss: 6.3614e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0015 - val_loss: 6.9873e-04\n",
      "✅ Model and scaler saved for TOP.BK\n",
      "\n",
      "📦 Training model for GPSC.BK using resource config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.1036 - val_loss: 0.0028\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0089 - val_loss: 0.0120\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0051 - val_loss: 0.0088\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0043 - val_loss: 0.0085\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0039 - val_loss: 0.0080\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0033 - val_loss: 0.0058\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0044 - val_loss: 0.0056\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0036 - val_loss: 0.0063\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0027 - val_loss: 0.0051\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0015 - val_loss: 9.7917e-04\n",
      "✅ Model and scaler saved for GPSC.BK\n",
      "\n",
      "📦 Training model for CPALL.BK using service config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 0.0794 - val_loss: 0.0089\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0116 - val_loss: 0.0085\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0107 - val_loss: 0.0071\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0096 - val_loss: 0.0056\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0090 - val_loss: 0.0061\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - loss: 0.0098 - val_loss: 0.0054\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.0075 - val_loss: 0.0047\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - loss: 0.0084 - val_loss: 0.0072\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0074 - val_loss: 0.0043\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0062 - val_loss: 0.0043\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0068 - val_loss: 0.0048\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0074 - val_loss: 0.0044\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0061 - val_loss: 0.0034\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0059 - val_loss: 0.0036\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0060 - val_loss: 0.0030\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0048 - val_loss: 0.0024\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0022 - val_loss: 0.0017\n",
      "✅ Model and scaler saved for CPALL.BK\n",
      "\n",
      "📦 Training model for AOT.BK using service config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - loss: 0.1406 - val_loss: 0.0065\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0127 - val_loss: 0.0036\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0103 - val_loss: 0.0059\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0101 - val_loss: 0.0034\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0100 - val_loss: 0.0031\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.0091 - val_loss: 0.0040\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0083 - val_loss: 0.0032\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0074 - val_loss: 0.0038\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0072 - val_loss: 0.0025\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0067 - val_loss: 0.0024\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0068 - val_loss: 0.0025\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0063 - val_loss: 0.0022\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0061 - val_loss: 0.0021\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0062 - val_loss: 0.0021\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - loss: 0.0060 - val_loss: 0.0027\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0057 - val_loss: 0.0019\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0056 - val_loss: 0.0019\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0050 - val_loss: 0.0025\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.0047 - val_loss: 0.0018\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0045 - val_loss: 0.0017\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0045 - val_loss: 0.0017\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0046 - val_loss: 0.0016\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0040 - val_loss: 0.0015\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0043 - val_loss: 0.0015\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0043 - val_loss: 0.0014\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0042 - val_loss: 0.0014\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.0037 - val_loss: 0.0014\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0049 - val_loss: 0.0014\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0039 - val_loss: 0.0013\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0035 - val_loss: 0.0013\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - loss: 0.0036 - val_loss: 0.0013\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0041 - val_loss: 0.0012\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.0033 - val_loss: 0.0012\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0036 - val_loss: 0.0011\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0035 - val_loss: 0.0010\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0027 - val_loss: 0.0010\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0026 - val_loss: 0.0010\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0029 - val_loss: 0.0012\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0025 - val_loss: 9.4739e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.0027 - val_loss: 9.5294e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - loss: 0.0027 - val_loss: 0.0011\n",
      "✅ Model and scaler saved for AOT.BK\n",
      "\n",
      "📦 Training model for BDMS.BK using service config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - loss: 0.0630 - val_loss: 0.0019\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0081 - val_loss: 0.0018\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0060 - val_loss: 0.0029\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0058 - val_loss: 0.0020\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0052 - val_loss: 0.0016\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0042 - val_loss: 0.0033\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0046 - val_loss: 0.0018\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0040 - val_loss: 0.0014\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.0038 - val_loss: 0.0013\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - loss: 0.0035 - val_loss: 0.0014\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - loss: 0.0027 - val_loss: 0.0054\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0038 - val_loss: 0.0011\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0025 - val_loss: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0021 - val_loss: 9.8766e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - loss: 0.0023 - val_loss: 9.9217e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0015 - val_loss: 9.6267e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0016 - val_loss: 9.9156e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0014 - val_loss: 9.6473e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0017 - val_loss: 9.3920e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0020 - val_loss: 9.3544e-04\n",
      "✅ Model and scaler saved for BDMS.BK\n",
      "\n",
      "📦 Training model for HMPRO.BK using service config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 102ms/step - loss: 0.1711 - val_loss: 0.0049\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0128 - val_loss: 0.0097\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0087 - val_loss: 0.0089\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0094 - val_loss: 0.0051\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0078 - val_loss: 0.0052\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0077 - val_loss: 0.0051\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0071 - val_loss: 0.0085\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0069 - val_loss: 0.0058\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0066 - val_loss: 0.0045\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0072 - val_loss: 0.0057\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0055 - val_loss: 0.0066\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 0.0058 - val_loss: 0.0030\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0065 - val_loss: 0.0035\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0058 - val_loss: 0.0036\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0037 - val_loss: 0.0058\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "✅ Model and scaler saved for HMPRO.BK\n",
      "\n",
      "📦 Training model for MINT.BK using service config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 104ms/step - loss: 0.1186 - val_loss: 0.0038\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0132 - val_loss: 0.0025\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0097 - val_loss: 0.0021\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0099 - val_loss: 0.0021\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0095 - val_loss: 0.0019\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0080 - val_loss: 0.0023\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0076 - val_loss: 0.0050\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0095 - val_loss: 0.0017\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0075 - val_loss: 0.0016\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0060 - val_loss: 0.0017\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0066 - val_loss: 0.0015\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0063 - val_loss: 0.0015\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0064 - val_loss: 0.0014\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0066 - val_loss: 0.0014\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0068 - val_loss: 0.0027\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0051 - val_loss: 0.0018\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0058 - val_loss: 0.0021\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0051 - val_loss: 0.0013\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0050 - val_loss: 0.0015\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0046 - val_loss: 0.0013\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0047 - val_loss: 0.0019\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0049 - val_loss: 0.0013\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0043 - val_loss: 0.0014\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0046 - val_loss: 0.0013\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0049 - val_loss: 0.0015\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0044 - val_loss: 0.0017\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0051 - val_loss: 0.0018\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0043 - val_loss: 0.0013\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0043 - val_loss: 0.0017\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0038 - val_loss: 0.0014\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0040 - val_loss: 0.0012\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0037 - val_loss: 0.0014\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0044 - val_loss: 0.0022\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0039 - val_loss: 0.0012\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0038 - val_loss: 0.0011\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0035 - val_loss: 0.0015\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0034 - val_loss: 0.0013\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0034 - val_loss: 0.0010\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0027 - val_loss: 0.0010\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0034 - val_loss: 9.7940e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0029 - val_loss: 9.4381e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0028 - val_loss: 9.4708e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "✅ Model and scaler saved for MINT.BK\n",
      "\n",
      "📦 Training model for ADVANC.BK using tech config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - loss: 0.0258 - val_loss: 0.0125\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0019 - val_loss: 5.8938e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0013 - val_loss: 7.1010e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0011 - val_loss: 5.5436e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0012 - val_loss: 5.3007e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0011 - val_loss: 8.4825e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0010 - val_loss: 5.0232e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 9.0780e-04 - val_loss: 0.0012\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 8.2096e-04 - val_loss: 0.0013\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0010 - val_loss: 5.4364e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 9.6131e-04 - val_loss: 0.0011\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 8.7251e-04 - val_loss: 6.4051e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 8.3368e-04 - val_loss: 0.0011\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 8.8730e-04 - val_loss: 5.8726e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 9.4175e-04 - val_loss: 4.7485e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 8.1701e-04 - val_loss: 8.5548e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 7.4608e-04 - val_loss: 4.9482e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 8.5544e-04 - val_loss: 0.0013\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 8.1521e-04 - val_loss: 6.8377e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 7.9923e-04 - val_loss: 7.7268e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 7.9453e-04 - val_loss: 4.0036e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 7.3728e-04 - val_loss: 4.4475e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 7.5507e-04 - val_loss: 4.0099e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 7.3176e-04 - val_loss: 3.6704e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 6.7604e-04 - val_loss: 5.3822e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 6.6884e-04 - val_loss: 0.0011\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 7.8565e-04 - val_loss: 6.3677e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 7.8415e-04 - val_loss: 4.1303e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 7.4930e-04 - val_loss: 3.3802e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 7.2024e-04 - val_loss: 4.8536e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 6.5834e-04 - val_loss: 3.2778e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 7.0162e-04 - val_loss: 6.9644e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 6.2918e-04 - val_loss: 3.8116e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 5.5542e-04 - val_loss: 3.8794e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 6.8941e-04 - val_loss: 3.0430e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 6.1859e-04 - val_loss: 2.9351e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 5.4278e-04 - val_loss: 3.9397e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 5.5875e-04 - val_loss: 3.1116e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.8554e-04 - val_loss: 6.8102e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 5.4709e-04 - val_loss: 2.7843e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 5.8510e-04 - val_loss: 5.9320e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 5.0973e-04 - val_loss: 2.8159e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 5.6875e-04 - val_loss: 2.8251e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 5.0904e-04 - val_loss: 4.8022e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 5.6816e-04 - val_loss: 5.3539e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 5.2813e-04 - val_loss: 2.6506e-04\n",
      "✅ Model and scaler saved for ADVANC.BK\n",
      "\n",
      "📦 Training model for TRUE.BK using tech config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - loss: 0.0189 - val_loss: 0.0019\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0010 - val_loss: 9.7850e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 9.6505e-04 - val_loss: 8.9723e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 9.2407e-04 - val_loss: 0.0011\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0015 - val_loss: 7.9905e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 8.6766e-04 - val_loss: 9.4726e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 7.5437e-04 - val_loss: 0.0011\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 9.7044e-04 - val_loss: 0.0024\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0012 - val_loss: 9.6903e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 8.9811e-04 - val_loss: 0.0014\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 9.0611e-04 - val_loss: 9.5443e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 8.5302e-04 - val_loss: 7.0030e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 5.9743e-04 - val_loss: 6.9237e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0011 - val_loss: 8.5152e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0012 - val_loss: 9.4713e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 8.3203e-04 - val_loss: 8.1252e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 8.6586e-04 - val_loss: 9.5140e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 8.1205e-04 - val_loss: 0.0011\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0011 - val_loss: 5.9142e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 6.8649e-04 - val_loss: 6.9051e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 5.7002e-04 - val_loss: 8.1978e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.4256e-04 - val_loss: 5.5569e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 7.6843e-04 - val_loss: 5.4523e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 5.8817e-04 - val_loss: 5.3264e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0010 - val_loss: 7.2467e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 9.1188e-04 - val_loss: 9.2629e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 7.4765e-04 - val_loss: 7.8954e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 5.0335e-04 - val_loss: 5.7104e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.4770e-04 - val_loss: 5.1528e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 9.2013e-04 - val_loss: 5.0838e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 7.6255e-04 - val_loss: 4.9065e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 5.7600e-04 - val_loss: 5.6710e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 6.1168e-04 - val_loss: 4.8118e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 5.9359e-04 - val_loss: 5.5391e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 5.4256e-04 - val_loss: 7.4189e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 7.7744e-04 - val_loss: 0.0011\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 5.0766e-04 - val_loss: 5.5845e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 6.3741e-04 - val_loss: 5.7880e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 6.4389e-04 - val_loss: 4.6579e-04\n",
      "✅ Model and scaler saved for TRUE.BK\n",
      "\n",
      "📦 Training model for DELTA.BK using tech config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - loss: 0.0230 - val_loss: 0.0024\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 9.5229e-04 - val_loss: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 9.1332e-04 - val_loss: 9.1764e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 9.5675e-04 - val_loss: 0.0013\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0010 - val_loss: 8.6320e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 9.4726e-04 - val_loss: 8.2882e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 7.1386e-04 - val_loss: 0.0011\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0011 - val_loss: 8.4036e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 9.2491e-04 - val_loss: 8.3818e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 7.7819e-04 - val_loss: 0.0011\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 7.6972e-04 - val_loss: 7.8499e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 7.3982e-04 - val_loss: 7.7325e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 8.2576e-04 - val_loss: 0.0012\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 8.5349e-04 - val_loss: 7.6122e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 6.3276e-04 - val_loss: 0.0013\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 8.4636e-04 - val_loss: 7.0820e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 7.5831e-04 - val_loss: 8.7488e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0010 - val_loss: 6.8546e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 8.9197e-04 - val_loss: 7.0453e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 9.8465e-04 - val_loss: 6.7075e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.0366e-04 - val_loss: 6.6282e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 7.4324e-04 - val_loss: 6.8387e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 6.6192e-04 - val_loss: 9.5179e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 9.1850e-04 - val_loss: 0.0010\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 6.3926e-04 - val_loss: 7.2956e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.6650e-04 - val_loss: 6.7156e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 6.8017e-04 - val_loss: 6.2031e-04\n",
      "✅ Model and scaler saved for DELTA.BK\n",
      "\n",
      "📦 Training model for CCET.BK using tech config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - loss: 0.0035 - val_loss: 9.6040e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 6.2164e-04 - val_loss: 5.2331e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 2.5995e-04 - val_loss: 5.2829e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 2.5373e-04 - val_loss: 4.7200e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 2.3589e-04 - val_loss: 4.3729e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 2.4249e-04 - val_loss: 4.2303e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 2.2012e-04 - val_loss: 4.0271e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.8897e-04 - val_loss: 4.8486e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 2.1550e-04 - val_loss: 3.7418e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 1.8861e-04 - val_loss: 3.4437e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 2.1231e-04 - val_loss: 3.7684e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 1.8985e-04 - val_loss: 3.2586e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 1.6376e-04 - val_loss: 3.2297e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 1.6291e-04 - val_loss: 2.9916e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 1.4031e-04 - val_loss: 3.0267e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 1.6211e-04 - val_loss: 2.7798e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 1.4915e-04 - val_loss: 2.7567e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 1.5704e-04 - val_loss: 3.2691e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 1.6292e-04 - val_loss: 2.6449e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 1.5352e-04 - val_loss: 2.7781e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 1.3464e-04 - val_loss: 2.6411e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 1.4147e-04 - val_loss: 2.4493e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 1.4099e-04 - val_loss: 2.4787e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 1.3619e-04 - val_loss: 2.4626e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 1.4000e-04 - val_loss: 2.3821e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 1.2864e-04 - val_loss: 2.3464e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 1.5788e-04 - val_loss: 2.2820e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.2783e-04 - val_loss: 2.2773e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.3062e-04 - val_loss: 2.4320e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.1425e-04 - val_loss: 2.1335e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.2670e-04 - val_loss: 2.2660e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 1.1046e-04 - val_loss: 2.0794e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.2352e-04 - val_loss: 2.2798e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.4061e-04 - val_loss: 2.0964e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.4628e-04 - val_loss: 2.1401e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.2782e-04 - val_loss: 2.0582e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.0815e-04 - val_loss: 2.0606e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 1.2589e-04 - val_loss: 1.9213e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 1.1143e-04 - val_loss: 1.9282e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 1.1367e-04 - val_loss: 1.8418e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.1445e-04 - val_loss: 2.0005e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.2151e-04 - val_loss: 2.0971e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 1.2623e-04 - val_loss: 1.8229e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 1.0249e-04 - val_loss: 1.9938e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.2904e-04 - val_loss: 1.8131e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.2075e-04 - val_loss: 1.7339e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 1.0203e-04 - val_loss: 1.9719e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 9.7893e-05 - val_loss: 1.8009e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.1352e-04 - val_loss: 1.7124e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.0800e-04 - val_loss: 2.0696e-04\n",
      "✅ Model and scaler saved for CCET.BK\n",
      "\n",
      "📦 Training model for KCE.BK using tech config\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 0.1054 - val_loss: 0.0028\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0103 - val_loss: 0.0041\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0055 - val_loss: 0.0022\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0050 - val_loss: 0.0020\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0043 - val_loss: 0.0017\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0041 - val_loss: 0.0017\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0037 - val_loss: 0.0015\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0039 - val_loss: 0.0015\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0040 - val_loss: 0.0017\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0034 - val_loss: 0.0015\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0038 - val_loss: 0.0013\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0034 - val_loss: 0.0013\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0033 - val_loss: 0.0013\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0037 - val_loss: 0.0014\n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0030 - val_loss: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0026 - val_loss: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0025 - val_loss: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0023 - val_loss: 9.1957e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0023 - val_loss: 8.4529e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0025 - val_loss: 9.1266e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0021 - val_loss: 8.7883e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0021 - val_loss: 8.9985e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0021 - val_loss: 8.1216e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0019 - val_loss: 9.0599e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0020 - val_loss: 9.9562e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0019 - val_loss: 8.7666e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0020 - val_loss: 8.5604e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0020 - val_loss: 7.6881e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0016 - val_loss: 7.4419e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0019 - val_loss: 7.5944e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0018 - val_loss: 7.3366e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0016 - val_loss: 7.4938e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0019 - val_loss: 7.5083e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "✅ Model and scaler saved for KCE.BK\n",
      "\n",
      "✅ All models tuned, trained, and evaluated!\n"
     ]
    }
   ],
   "source": [
    "# train all the stocks using tuner for each industry\n",
    "for industry, stocks in industries.items():\n",
    "    for stock in stocks:\n",
    "        print(f\"\\n📦 Training model for {stock} using {industry} config\")\n",
    "\n",
    "        data_file = os.path.join(\"data\", industry, f\"{stock}.csv\")\n",
    "        if not os.path.exists(data_file):\n",
    "            print(f\"⚠️ File not found: {data_file}\")\n",
    "            continue\n",
    "\n",
    "        df = pd.read_csv(data_file)\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        df.set_index('Date', inplace=True)\n",
    "        df = df[['Close']]\n",
    "\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled_data = scaler.fit_transform(df)\n",
    "        train_data, test_data = train_test_split(scaled_data, train_size=0.8, shuffle=False)\n",
    "\n",
    "        if len(test_data) < 60:\n",
    "            print(f\"⚠️ Not enough test data for {stock}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        x_train, y_train = create_sequences(train_data)\n",
    "        x_test, y_test = create_sequences(test_data)\n",
    "\n",
    "        if len(x_train) == 0 or len(x_test) == 0:\n",
    "            print(f\"⚠️ No sequences generated for {stock}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        config = industry_configs[industry]\n",
    "        model = build_model(\n",
    "            input_shape=(x_train.shape[1], 1),\n",
    "            lstm_units=config['lstm_units'],\n",
    "            dropout_rate=config['dropout_rate'],\n",
    "            dense_units=config['dense_units']\n",
    "        )\n",
    "\n",
    "        model_dir = os.path.join(\"models\", industry)\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        model_file = os.path.join(model_dir, f\"{stock}_model.keras\")\n",
    "        scaler_file = os.path.join(model_dir, f\"{stock}_scaler.pkl\")\n",
    "\n",
    "        early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "        model_checkpoint = ModelCheckpoint(model_file, monitor='loss', save_best_only=True)\n",
    "\n",
    "        model.fit(\n",
    "            x_train, y_train,\n",
    "            batch_size=32,\n",
    "            epochs=50,\n",
    "            validation_split=0.2,\n",
    "            callbacks=[early_stop, model_checkpoint]\n",
    "        )\n",
    "\n",
    "        model.save(model_file)\n",
    "        with open(scaler_file, 'wb') as f:\n",
    "            pickle.dump(scaler, f)\n",
    "        print(f\"✅ Model and scaler saved for {stock}\")\n",
    "\n",
    "print(\"\\n✅ All models tuned, trained, and evaluated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f86b40-0dc1-4cdd-85bc-131890e419ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Train as Individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "2cfca563-7a00-4c2a-88aa-ff922a2e93db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>CCET.BK</th>\n",
       "      <th>CCET.BK</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>1.657060</td>\n",
       "      <td>24460336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>1.633388</td>\n",
       "      <td>5586388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-06</th>\n",
       "      <td>1.633388</td>\n",
       "      <td>3754609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-09</th>\n",
       "      <td>1.633388</td>\n",
       "      <td>2824013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-10</th>\n",
       "      <td>1.668897</td>\n",
       "      <td>3381578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-25</th>\n",
       "      <td>6.150000</td>\n",
       "      <td>54943700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-26</th>\n",
       "      <td>6.450000</td>\n",
       "      <td>94911900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-27</th>\n",
       "      <td>6.550000</td>\n",
       "      <td>64183800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-28</th>\n",
       "      <td>6.050000</td>\n",
       "      <td>59948900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-31</th>\n",
       "      <td>5.850000</td>\n",
       "      <td>58043000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2004 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price          Close    Volume\n",
       "Ticker       CCET.BK   CCET.BK\n",
       "Date                          \n",
       "2017-01-04  1.657060  24460336\n",
       "2017-01-05  1.633388   5586388\n",
       "2017-01-06  1.633388   3754609\n",
       "2017-01-09  1.633388   2824013\n",
       "2017-01-10  1.668897   3381578\n",
       "...              ...       ...\n",
       "2025-03-25  6.150000  54943700\n",
       "2025-03-26  6.450000  94911900\n",
       "2025-03-27  6.550000  64183800\n",
       "2025-03-28  6.050000  59948900\n",
       "2025-03-31  5.850000  58043000\n",
       "\n",
       "[2004 rows x 2 columns]"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the latest preprocessed data from CSV file\n",
    "# file_path = os.path.join(\"data\", \"Fincial\", \"SCB.BK.csv\")\n",
    "import yfinance as yf\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# file_path = os.path.join(\"data\", \"Indus\", \"PTTGC.BK.csv\")\n",
    "\n",
    "# Load and preprocess the data\n",
    "# df = pd.read_csv(file_path)\n",
    "df = yf.download(\"CCET.BK\", start='2017-01-01', end='2025-04-01', auto_adjust=True) #show adjusted close price\n",
    "# df['Date'] = pd.to_datetime(df['Date'])\n",
    "# df.set_index('Date', inplace=True)\n",
    "df = df[['Close', 'Volume']]\n",
    "# df = df[df.index >= '2021-01-01']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "911a77d0-d75c-41b5-ba25-ca12e62bbd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.076941</td>\n",
       "      <td>0.062057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.074464</td>\n",
       "      <td>0.014173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.074464</td>\n",
       "      <td>0.009526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.074464</td>\n",
       "      <td>0.007165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.078179</td>\n",
       "      <td>0.008579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.547036</td>\n",
       "      <td>0.139394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>0.578425</td>\n",
       "      <td>0.240795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>0.588888</td>\n",
       "      <td>0.162837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>0.536573</td>\n",
       "      <td>0.152093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>0.515647</td>\n",
       "      <td>0.147257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2004 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Close    Volume\n",
       "0     0.076941  0.062057\n",
       "1     0.074464  0.014173\n",
       "2     0.074464  0.009526\n",
       "3     0.074464  0.007165\n",
       "4     0.078179  0.008579\n",
       "...        ...       ...\n",
       "1999  0.547036  0.139394\n",
       "2000  0.578425  0.240795\n",
       "2001  0.588888  0.162837\n",
       "2002  0.536573  0.152093\n",
       "2003  0.515647  0.147257\n",
       "\n",
       "[2004 rows x 2 columns]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale to range 0, 1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))  # Normalize between 0 and 1\n",
    "scaled_data = scaler.fit_transform(df[['Close', 'Volume']])\n",
    "processed_data = pd.DataFrame(scaled_data, columns=['Close', 'Volume'])\n",
    "processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "ee18c6a1-d362-4cc2-9a7a-eee57c049bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (1513, 90, 2)\n",
      "y_train shape: (1513,)\n",
      "x_test shape: (311, 90, 2)\n",
      "y_test shape: (311,)\n"
     ]
    }
   ],
   "source": [
    "# Split into the training and testing sets\n",
    "train_data, test_data = train_test_split(scaled_data, train_size=0.8, shuffle=False)\n",
    "\n",
    "def create_sequences(data, sequence_length=90):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(sequence_length, len(data)):\n",
    "        X.append(data[i-sequence_length:i])         # All features for past 60 days\n",
    "        y.append(data[i, 0])                         # Only Close price is the target (1st column)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "x_train, y_train = create_sequences(train_data)\n",
    "x_test, y_test = create_sequences(test_data)\n",
    "\n",
    "# Print dataset shapes\n",
    "print(f\"x_train shape: {x_train.shape}\")  # Expecting (samples, 60, 2)\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\" if len(x_test) > 0 else \"⚠️ No test set available.\")\n",
    "print(f\"y_test shape: {y_test.shape}\" if len(y_test) > 0 else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "6501975a-dd41-47d5-8fdf-4cb8b5421e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    model = Sequential()\n",
    "    hp_units = hp.Choice('lstm_units', [32, 50, 64, 100])\n",
    "    hp_dropout = hp.Choice('dropout_rate', [0.1, 0.2, 0.3])\n",
    "    hp_dense = hp.Choice('dense_units', [16, 25, 50])\n",
    "\n",
    "    model.add(LSTM(units=hp_units, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    model.add(Dropout(hp_dropout))\n",
    "\n",
    "    model.add(LSTM(units=hp_units, return_sequences=True))\n",
    "    model.add(Dropout(hp_dropout))\n",
    "\n",
    "    model.add(LSTM(units=hp_units))\n",
    "    model.add(Dropout(hp_dropout))\n",
    "\n",
    "    model.add(Dense(units=hp_dense))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "78df04bc-02e0-40fb-a0da-ca1c24a72d74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from tuning_logs/ccet_multi_feature_lstm5/tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model and scaler saved to: models/tech\n",
      "Best LSTM Units: 100\n",
      "Best Dropout Rate: 0.3\n",
      "Best Dense Units: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 28 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "# Run the tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    model_builder,\n",
    "    objective='val_loss',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=1,\n",
    "    directory='tuning_logs',\n",
    "    project_name='ccet_multi_feature_lstm5'\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Start hyperparameter tuning\n",
    "tuner.search(\n",
    "    x_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# ✅ Retrieve best model and hyperparameters\n",
    "best_model = tuner.get_best_models(1)[0]\n",
    "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "\n",
    "# ✅ Define output directory and file paths\n",
    "output_dir = os.path.join(\"models\", \"tech\")  \n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "model_file = os.path.join(output_dir, \"CCET.BK_model.keras\")\n",
    "scaler_file = os.path.join(output_dir, \"CCET.BK_scaler.pkl\")\n",
    "\n",
    "# ✅ Save best model and scaler\n",
    "best_model.save(model_file)\n",
    "with open(scaler_file, 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(f\"✅ Model and scaler saved to: {output_dir}\")\n",
    "print(f\"Best LSTM Units: {best_hp.get('lstm_units')}\")\n",
    "print(f\"Best Dropout Rate: {best_hp.get('dropout_rate')}\")\n",
    "print(f\"Best Dense Units: {best_hp.get('dense_units')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "a71f1d4d-6a2e-45f0-b07a-39abd824815f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 130ms/step\n",
      "\n",
      "📊 Evaluation Metrics:\n",
      "   - Mean Absolute Error (MAE): 0.3641\n",
      "   - Root Mean Squared Error (RMSE): 0.5978\n",
      "   - Mean Absolute Percentage Error (MAPE): 6.40%\n"
     ]
    }
   ],
   "source": [
    "test_predictions = best_model.predict(x_test)\n",
    "\n",
    "# ⚠️ Rescale predictions and true labels\n",
    "# If you used multiple features like ['Close', 'Volume'], pad the missing features with 0s before inverse_transform\n",
    "num_features = scaler.n_features_in_\n",
    "\n",
    "test_predictions_padded = np.concatenate(\n",
    "    [test_predictions, np.zeros((len(test_predictions), num_features - 1))],\n",
    "    axis=1\n",
    ")\n",
    "y_test_padded = np.concatenate(\n",
    "    [y_test.reshape(-1, 1), np.zeros((len(y_test), num_features - 1))],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Inverse transform back to original scale\n",
    "test_predictions_rescaled = scaler.inverse_transform(test_predictions_padded)[:, 0]\n",
    "y_test_rescaled = scaler.inverse_transform(y_test_padded)[:, 0]\n",
    "\n",
    "mse = mean_squared_error(y_test_rescaled, test_predictions_rescaled)\n",
    "mae = mean_absolute_error(y_test_rescaled, test_predictions_rescaled)\n",
    "rmse = np.sqrt(mse)\n",
    "mape = np.mean(np.abs((y_test_rescaled - test_predictions_rescaled) / y_test_rescaled)) * 100\n",
    "\n",
    "print(\"\\n📊 Evaluation Metrics:\")\n",
    "# print(f\"   - Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"   - Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"   - Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"   - Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a679d848-8a19-45d3-88f6-80bfb7168ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "            Predicted Close\n",
      "2025-04-02       159.100616\n",
      "2025-04-03       158.476242\n",
      "2025-04-04       157.503006\n",
      "2025-04-05       156.327682\n",
      "2025-04-06       155.069092\n",
      "2025-04-07       153.803604\n",
      "2025-04-08       152.574097\n",
      "2025-04-09       151.401932\n",
      "2025-04-10       150.296417\n",
      "2025-04-11       149.260239\n",
      "2025-04-12       148.292572\n",
      "2025-04-13       147.390503\n",
      "2025-04-14       146.549805\n",
      "2025-04-15       145.765320\n",
      "2025-04-16       145.031387\n",
      "2025-04-17       144.342102\n",
      "2025-04-18       143.691620\n",
      "2025-04-19       143.074280\n",
      "2025-04-20       142.484955\n",
      "2025-04-21       141.918945\n",
      "2025-04-22       141.372208\n",
      "2025-04-23       140.841263\n",
      "2025-04-24       140.323288\n",
      "2025-04-25       139.816010\n",
      "2025-04-26       139.317673\n",
      "2025-04-27       138.826996\n",
      "2025-04-28       138.343079\n",
      "2025-04-29       137.865341\n",
      "2025-04-30       137.393494\n",
      "2025-05-01       136.927383\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Generate predictions for 30-day forecast\n",
    "\n",
    "# Take the last 60 days from the dataset for generating future predictions\n",
    "last_60_days = scaled_data[-60:]\n",
    "\n",
    "# Reshape last_60_days to fit the model input shape\n",
    "x_future = last_60_days.reshape((1, last_60_days.shape[0], 1))\n",
    "\n",
    "# Generate predictions\n",
    "predictions = []\n",
    "for _ in range(30):\n",
    "    pred = model.predict(x_future) # Predict the next day\n",
    "    predictions.append(pred[0,0]) # Append the prediction to the list\n",
    "    \n",
    "    # Update x_future by removing the first value and appending the prediction at the end\n",
    "    x_future = np.append(x_future[:, 1:, :], np.array([[pred[0, 0]]]).reshape(1, 1, 1), axis=1)\n",
    "\n",
    "# Inverse transform the predictions to get them back to the original scale\n",
    "predictions = scaler.inverse_transform(np.array(predictions).reshape(-1, 1))\n",
    "\n",
    "# Convert predictions to a DataFrame\n",
    "future_dates = pd.date_range(start=df.index[-1] + pd.Timedelta(days=1), periods=30)\n",
    "predictions_df = pd.DataFrame(predictions, index=future_dates, columns=['Predicted Close'])\n",
    "print(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "50bf5c67-c870-493e-a6bb-dfcc847a7f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot historical data and future predictions for comparison\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df['Close'], label='Historical Prices')\n",
    "plt.plot(predictions_df, label='30-Day Forecast', linestyle='--')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6de2c725-0f0e-4142-8d64-8222e7eaae32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step \n",
      "Mean Absolute Error: 8.327432929285603\n",
      "Root Mean Squared Error: 11.550927561145174\n",
      "Mean Absolute Percentage Error (MAPE): 6.981642318056467%\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Evaluationg model\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = model.predict(x_test)\n",
    "\n",
    "# Inverse transform the predictions to get them back to the original scale\n",
    "test_predictions = scaler.inverse_transform(test_predictions)\n",
    "y_test_rescaled = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "mse = mean_squared_error(y_test_rescaled, test_predictions)\n",
    "mae = mean_absolute_error(y_test_rescaled, test_predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "mape = np.mean(np.abs((y_test_rescaled - test_predictions) / y_test_rescaled)) * 100\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c429558-9e93-45d6-984e-b48ff11ed004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the actual vs. predicted prices\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test_rescaled, label='Actual Prices')\n",
    "plt.plot(test_predictions, label='Predicted Prices')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.title('Actual vs. Predicted Stock Prices')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
